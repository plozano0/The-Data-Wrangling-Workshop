{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba13a8d",
   "metadata": {},
   "source": [
    "*  DSC 540-T302 Data Preparation\n",
    "*  Week 9 & 10 Exercise\n",
    "*  Peter Lozano"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6993a",
   "metadata": {},
   "source": [
    "# Activity 7.01 Extracting the Top 100 e-books from Gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb4cfd",
   "metadata": {},
   "source": [
    "I have to extract the Top 100 e-books from [Project Gutenberg](https://www.gutenberg.org/browse/scores/top) using web scraping techniques. I will use Python along with the BeautifulSoup and requests libraries to accomplish this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562e66a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c6e68b",
   "metadata": {},
   "source": [
    "## Read HTML from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b7ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read HTML from the URL\n",
    "gutenberg_url = \"https://www.gutenberg.org/browse/scores/top\"\n",
    "# Get the page content\n",
    "response = requests.get(gutenberg_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d9334",
   "metadata": {},
   "source": [
    "## Write a small function to check the status of the web request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff9331",
   "metadata": {},
   "source": [
    "It's always good practice to check the status of the request to ensure that the page was retrieved successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking the status of the web request\n",
    "def check_request_status(response):\n",
    "    # 200 status code indicates that the request was successful.\n",
    "    if response.status_code == 200:\n",
    "        print(\"Request was successful.\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0acd3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request was successful.\n"
     ]
    }
   ],
   "source": [
    "check_request_status(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf9643",
   "metadata": {},
   "source": [
    "A **200** status code indicates that the request was successful. Any other status code indicates that there was an issue with the request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a808c8",
   "metadata": {},
   "source": [
    "## Decode the response and pass this on to **BeautifulSoup** for HTML parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b022a9b",
   "metadata": {},
   "source": [
    "The response variable contains the HTML content of the page. However, just passing the response to BeautifulSoup may not work as expected because the content is in bytes format. Therefore, we need to decode the response content by accessing the contents attribute before passing it to BeautifulSoup for parsing.\n",
    "\n",
    "I will show you what the response variable looks like before decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd695be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aabec82",
   "metadata": {},
   "source": [
    "As you can see, the response variable appears to only contain the response status but not the actual HTML content. This is because the response variable is an object that contains various attributes, including the status code, headers, and content.\n",
    "\n",
    "To access the actual HTML content, we need to use the `.content` attribute of the response object. This will give us the raw bytes of the HTML content, which we can then decode to a string format if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response and pass this on to BeautifulSoup for HTML parsing.\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b9289",
   "metadata": {},
   "source": [
    "Using the **BeautifulSoup** library, I will parse the HTML content to extract the relevant information about the top 100 e-books, such as titles and authors. I do this by passing the `html.parser` argument to the BeautifulSoup constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268bcc8",
   "metadata": {},
   "source": [
    "## Find all the **href** tags and store them in a list of links. Check what the list looks like -- print the first 30 elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ff402",
   "metadata": {},
   "source": [
    "Now I have to find the tags that contain the information about the top 100 e-books. After inspecting the HTML structure of the page, I found that the top 100 e-books are listed under an `<ol>` tag with a preceding `<h2>` tag that contains the text \"Top 100 EBooks yesterday\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f369488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/', '/donate/', '/about/', '/about/contact_information.html', '/about/background/', '/help/mobile.html', '/help/', '/ebooks/offline_catalogs.html', '/donate/', '/browse/scores/top', '/ebooks/categories', '/ebooks/bookshelf/', '/ebooks/', '/browse/scores/top', '/ebooks/categories', '/about/pretty-pictures.html', '#books-last1', '#books-last7', '#books-last30', '#authors-last1', '#authors-last7', '#authors-last30', '/ebooks/84', '/ebooks/2701', '/ebooks/1342', '/ebooks/1513', '/ebooks/43', '/ebooks/16328', '/ebooks/2641', '/ebooks/100']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store links\n",
    "lst_links = []\n",
    "# Find all the href tags and store them in the list\n",
    "for link in soup.find_all('a', href=True):\n",
    "    lst_links.append(link['href'])\n",
    "\n",
    "# Print the first 30 elements of the list\n",
    "print(lst_links[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40952980",
   "metadata": {},
   "source": [
    "## Use a regular expression to find the numeric digits in these links and loop over the appropriate range and use a regex to find the numeric digits in the link (href) string. Use the `findall()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01ce05",
   "metadata": {},
   "source": [
    "I know that all the books contain \"ebooks/\" followed by the numeric digits that represent the file numbers for the eBooks. I will use a regular expression to extract these numeric digits from the links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['84', '2701', '1342', '1513', '43', '16328', '2641', '100', '11', '145', '37106', '2554', '64317', '67979', '768', '1260', '16389', '5197', '1080', '394', '2160', '1259', '6761', '6593', '2542', '4085', '844', '3207', '76', '174']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store file numbers\n",
    "file_numbers = []\n",
    "\n",
    "# Loop over the list of links to extract numeric digits using regex\n",
    "for link in lst_links:\n",
    "    # Matching 'ebooks/' followed by digits using findall()\n",
    "    match = re.findall(r'ebooks/(\\d+)', link)\n",
    "    if len(match) == 1:\n",
    "        # Appending the numeric digits (file number) to the list\n",
    "        file_numbers.append(match[0])\n",
    "print(file_numbers[:30])  # Print the first 30 file numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c114d9b8",
   "metadata": {},
   "source": [
    "## What does the **soup** object's text look like? Use the `.text()` method and print only the first 2,000 characters (do not print the whole thing, as it is too long)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ff95e",
   "metadata": {},
   "source": [
    "I can use the **soup** object's `.text` attribute to get the text content of the HTML document. This will give me a plain text representation of the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5040c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\nTop 100 | Project Gutenberg\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX\\n\\nGo!\\n\\n\\n\\n\\n\\n\\n\\n Donate \\n\\n\\n\\n\\n\\nAbout▼\\n\\nAbout Project Gutenberg \\nContact Us\\nHistory & Philosophy\\nKindle & eReaders\\nHelp Pages\\nOffline Catalogs\\nDonate\\n\\n\\n\\nFrequently Downloaded\\nMain Categories\\nReading Lists\\nSearch Options\\n\\n\\n\\nFrequently Downloaded\\nMain Categories\\n\\n\\n\\nFrequently Viewed or Downloaded\\nCalculated from the number of times each eBook gets\\ndownloaded. (Multiple downloads from the same Internet\\naddress on the same day count as one download. Addresses\\nthat download more than 100 eBooks in a day are considered\\nrobots and are not counted.)\\n\\nDownloaded Books\\n2026-01-211441835\\nlast 7 days7651346\\nlast 30 days36511933\\n\\nVisualizations and graphs are available as\\npretty pictures.\\n\\n\\nTop 100 EBooks: Yesterday - 7\\xa0days - 30\\xa0days\\nTop 100 Authors: Yesterday - 7\\xa0days - 30\\xa0days\\n\\nTop 100 EBooks yesterday\\n\\nFrankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (6236)\\nMoby Dick; Or, The Whale by Herman Melville (4229)\\nPride and Prejudice by Jane Austen (3143)\\nRomeo and Juliet by William Shakespeare (2622)\\nThe Strange Case of Dr. Jekyll and Mr. Hyde by Robert Louis Stevenson (2229)\\nBeowulf: An Anglo-Saxon Epic Poem (2181)\\nA Room with a View by E. M.  Forster (2120)\\nThe Complete Works of William Shakespeare by William Shakespeare (2093)\\nAlice's Adventures in Wonderland by Lewis Carroll (2067)\\nMiddlemarch by George Eliot (2014)\\nLittle Women; Or, Meg, Jo, Beth, and Amy by Louisa May Alcott (1945)\\nCrime and Punishment by Fyodor Dostoyevsky (1891)\\nThe Great Gatsby by F. Scott  Fitzgerald (1870)\\nThe Blue Castle: a novel by L. M.  Montgomery (1756)\\nWuthering Heights by Emily Brontë (1692)\\nJane Eyre: An Autobiography by Charlotte Brontë (1667)\\nThe Enchanted April by Elizabeth Von Arnim (1595)\\nMy Life — Volume 1 by Richard Wagner (1536)\\nA Modest Proposal by Jonathan Swift (1529)\\nCranford by Elizabeth Cleghorn Gaskell (1505)\\nThe Expedition of Humphry Clinker by T.  Smollett (1503)\\nTwenty years after by Alexandre D\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text[:2000]  # Print the first 2000 characters of the soup object's text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5e6ba",
   "metadata": {},
   "source": [
    "## Search the extracted text (using regex) from the **soup** object to find the names of the top 100 eBooks (yesterday's ranking)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fa517d",
   "metadata": {},
   "source": [
    "I will start by creating a temporary list to hold the strings of the top 100 eBook names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f58fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_titles_temp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2f7ca",
   "metadata": {},
   "source": [
    "## Create a starting index. It should point at the text Top 100 Ebooks yesterday. Use the **splitlines** method of **soup.text**. It splits the lines of the text of the **soup** object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5d0c0",
   "metadata": {},
   "source": [
    "Parsing through the HTML content, I found that the text \"Top 100 EBooks yesterday\" is located at line index 98. Therefore, I will set the starting index to 98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc48d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = soup.text.splitlines().index('Top 100 EBooks yesterday') # Returns 98 as the start index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2945d9",
   "metadata": {},
   "source": [
    "## Run the **for** loop from **1-100** to add the strings of the next **100** lines to this temporary list. **Hint**: use the **splitlines** method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c0567",
   "metadata": {},
   "source": [
    "I will pass the `start_index` through the for loop to extract the next 100 lines, which contain the eBook titles. This will result in a list of strings, each representing an eBook title along with its author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # Append the line at the calculated index to the temporary list\n",
    "    list_titles_temp.append(soup.text.splitlines()[start_index + 2 + i]) # +2 to skip the header lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e7ce6",
   "metadata": {},
   "source": [
    "## Use regex to extract only text from the name strings and append them to an empty list. Use **match** and **span** to find the indices and use them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af8248",
   "metadata": {},
   "source": [
    "Now that I have my temporary list of eBook titles with authors, I will use regular expressions to extract only the text portion of each title. This involves matching the alphabetic characters at the beginning of each string.\n",
    "\n",
    "This method is effective but has flaws. For example, if an eBook title contains special characters or numbers, those special characters from the book will be excluded from the final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbfb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_titles = []\n",
    "for i in range(100):\n",
    "    # Use regex to extract only the alphabetic characters from the beginning of each title\n",
    "    id1, id2 = re.match('^[a-zA-Z ]*',list_titles_temp[i]).span() # Span is to get the start and end index of the match\n",
    "    list_titles.append(list_titles_temp[i][id1:id2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18480b98",
   "metadata": {},
   "source": [
    "## Print the list of titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76e6d558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein\n",
      "Moby Dick\n",
      "Pride and Prejudice by Jane Austen \n",
      "Romeo and Juliet by William Shakespeare \n",
      "The Strange Case of Dr\n",
      "Beowulf\n",
      "A Room with a View by E\n",
      "The Complete Works of William Shakespeare by William Shakespeare \n",
      "Alice\n",
      "Middlemarch by George Eliot \n",
      "Little Women\n",
      "Crime and Punishment by Fyodor Dostoyevsky \n",
      "The Great Gatsby by F\n",
      "The Blue Castle\n",
      "Wuthering Heights by Emily Bront\n",
      "Jane Eyre\n",
      "The Enchanted April by Elizabeth Von Arnim \n",
      "My Life \n",
      "A Modest Proposal by Jonathan Swift \n",
      "Cranford by Elizabeth Cleghorn Gaskell \n",
      "The Expedition of Humphry Clinker by T\n",
      "Twenty years after by Alexandre Dumas and Auguste Maquet \n",
      "The Adventures of Ferdinand Count Fathom \n",
      "History of Tom Jones\n",
      "A Doll\n",
      "The Adventures of Roderick Random by T\n",
      "The Importance of Being Earnest\n",
      "Leviathan by Thomas Hobbes \n",
      "Adventures of Huckleberry Finn by Mark Twain \n",
      "The Picture of Dorian Gray by Oscar Wilde \n",
      "The Count of Monte Cristo by Alexandre Dumas and Auguste Maquet \n",
      "The King in Yellow by Robert W\n",
      "The Adventures of Tom Sawyer\n",
      "Dracula by Bram Stoker \n",
      "A Tale of Two Cities by Charles Dickens \n",
      "The Yellow Wallpaper by Charlotte Perkins Gilman \n",
      "The Brothers Karamazov by Fyodor Dostoyevsky \n",
      "The Adventures of Sherlock Holmes by Arthur Conan Doyle \n",
      "The Iliad by Homer \n",
      "Poisons\n",
      "Oedipus King of Thebes by Sophocles \n",
      "Great Expectations by Charles Dickens \n",
      "Thus Spake Zarathustra\n",
      "Anne of Green Gables by L\n",
      "Second Treatise of Government by John Locke \n",
      "The Prince by Niccol\n",
      "The Scarlet Letter by Nathaniel Hawthorne \n",
      "Simple Sabotage Field Manual by United States\n",
      "Walden\n",
      "The Confessions of St\n",
      "Fables of La Fontaine \n",
      "Grimms\n",
      "Complete Original Short Stories of Guy De Maupassant by Guy de Maupassant \n",
      "Moby Multiple Language Lists of Common Words by Grady Ward \n",
      "Metamorphosis by Franz Kafka \n",
      "White nights\n",
      "The Odyssey by Homer \n",
      "Narrative of the Life of Frederick Douglass\n",
      "Beyond Good and Evil by Friedrich Wilhelm Nietzsche \n",
      "Treasure Island by Robert Louis Stevenson \n",
      "A daughter of Heth by William Black \n",
      "The Interesting Narrative of the Life of Olaudah Equiano\n",
      "The Souls of Black Folk by W\n",
      "Ulysses by James Joyce \n",
      "A Christmas Carol in Prose\n",
      "The Works of Edgar Allan Poe \n",
      "Frankenstein\n",
      "The Republic by Plato \n",
      "The Black Hawk War Including a Review of Black Hawk\n",
      "War and Peace by graf Leo Tolstoy \n",
      "Tractatus Logico\n",
      "The Wonderful Wizard of Oz by L\n",
      "Modern English biography\n",
      "Doctrina Christiana \n",
      "Meditations by Emperor of Rome Marcus Aurelius \n",
      "Hamlet by William Shakespeare \n",
      "A Vagabond Journey Around the World\n",
      "\n",
      "Heart of Darkness by Joseph Conrad \n",
      "Anna Karenina by graf Leo Tolstoy \n",
      "Peter Pan \n",
      "The Jew and Other Stories by Ivan Sergeevich Turgenev \n",
      "The divine comedy by Dante Alighieri \n",
      "The Travels of Marco Polo \n",
      "Frankenstein\n",
      "On Liberty by John Stuart Mill \n",
      "The Hound of the Baskervilles by Arthur Conan Doyle \n",
      "A Short Biographical Dictionary of English Literature by John W\n",
      "Candide by Voltaire \n",
      "Belford\n",
      "\n",
      "Don Quixote by Miguel de Cervantes Saavedra \n",
      "A Study in Scarlet by Arthur Conan Doyle \n",
      "Paradise Lost by John Milton \n",
      "Sense and Sensibility by Jane Austen \n",
      "Gulliver\n",
      "The lesser Key of Solomon\n",
      "Through Siberia by Henry Lansdell \n",
      "Symposium by Plato \n",
      "The Art of War by active \n"
     ]
    }
   ],
   "source": [
    "for title in list_titles:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0ef3f",
   "metadata": {},
   "source": [
    "# Activity 7.02 Building Your Own Movie Database by Reading an API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dab10b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
